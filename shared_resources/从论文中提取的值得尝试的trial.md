### 从论文中提取的值得尝试的损失度量

#### 1. **平方L2损失（Squared L2 Loss）**

**指标**：

$$
\mathcal{L}_{\text{L2}}(\Delta_2) = \Delta_2^2
$$

其中，$\Delta_2 = |y_{\text{pred}} - y_{\text{true}}|$ 表示回归误差的绝对值（即 $L_2$ 范数的简化形式）。该损失是最基础的均方误差（MSE）的单样本版本，适用于误差分布接近正态的场景，对异常值敏感但计算高效。

#### 2. **伪Huber损失（Pseudo-Huber Loss）**

**指标**：

$$
\mathcal{L}_{\text{pseudo-Huber}}(\Delta_2; \delta) = \delta^2 \left( \sqrt{1 + \left( \frac{\Delta_2}{\delta} \right)^2} - 1 \right)
$$

其中，$\delta > 0$ 是平滑参数（控制损失的鲁棒性）。当 $\Delta_2 \ll \delta$ 时，损失近似为 $\frac{1}{2}\Delta_2^2$（类似L2损失）；当 $\Delta_2 \gg \delta$ 时，损失近似为 $\delta \cdot \Delta_2 - \frac{\delta^2}{2}$（线性增长，对异常值不敏感）。材料中提到当 $p=0.5$ 时，自适应加权损失类似此形式，可通过调整 $\delta$ 平衡精度与鲁棒性。

#### 3. **自适应加权L2损失（Adaptive Weighted L2 Loss）**

我们可以试一试 p = 0, 0.5, 1

**指标**：

$$
\mathcal{L}_{\text{adaptive}} = \text{sg}(w) \cdot w \cdot \Delta_2^2
$$

其中，权重 $w = \frac{1}{(\Delta_2^2 + c)^p}$，$p = 1 - \gamma$（$\gamma > 0$ 控制自适应程度），$c > 0$ 为小常数（如 $10^{-3}$ 防止分母为零）。该损失通过自适应降低大误差样本的权重（提升小误差样本的重要性），可视为对L2损失的改进，实验中可通过调整 $\gamma$ 和 $c$ 适配不同误差分布。

>在自适应加权L2损失中，参数 $p$ 是权重函数 $\mathcal{W}(\Delta_2) = (\Delta_2^2 + c)^{-p}$ 中的指数系数，其核心作用是**调节损失函数对不同误差大小样本的关注程度**。以下是具体解释：
>
>### **1. $p$ 的定义与来源**
>
>根据材料描述，权重 $w$ 被设定为：
>
>$$
>w = \frac{1}{(\Delta_2^2 + c)^p}
>$$
>
>其中 $c > 0$ 是防止分母为零的小常数（如 $10^{-3}$），而 $p$ 由超参数 $\gamma$ 直接控制，关系为：
>
>$$
>p = 1 - \gamma
>$$
>
>因此，$\gamma$ 是更上层的“自适应程度”参数，$p$ 是其衍生的指数参数。
>
>### **2. $p$ 对损失函数的影响**
>
>$p$ 通过控制权重随误差 $\Delta_2$（回归误差）的衰减速度，间接调节模型对不同误差样本的关注：
>
>-   **当 $p$ 较大时**（即 $\gamma = 1 - p$ 较小）：
>     权重 $w$ 随 $\Delta_2$ 的增大而**快速衰减**​（因为分母 $(\Delta_2^2 + c)^p$ 随 $\Delta_2$ 增长的速度更快）。此时，大误差样本的权重被显著降低，模型更关注小误差样本，损失函数对异常值更鲁棒。
>-   **当 $p$ 较小时**（即 $\gamma$ 较大）：
>     权重 $w$ 随 $\Delta_2$ 的增大而**缓慢衰减**​（分母增长较慢）。此时，大误差样本仍保留较高的权重，模型对大误差的惩罚更严格，更关注误差较大的样本。
>
>### **3. 典型取值与效果示例**
>
>结合 $\gamma$ 的物理意义（控制自适应程度），$p$ 的典型取值范围通常为 $(0, 1)$，对应不同的损失行为：
>
>-   **当 $p = 0.5$（即 $\gamma = 0.5$）**：
>     权重退化为 $w = 1/(\Delta_2^2 + c)^{0.5} = 1/\sqrt{\Delta_2^2 + c}$，此时损失类似于**伪Huber损失**​（材料中提到）。大误差样本的权重随 $\Delta_2$ 线性增长（而非平方增长），平衡了对异常值的鲁棒性和对小误差的拟合精度。
>-   **当 $p \to 1$（即 $\gamma \to 0$）**：(**这种情况**被论文证明很有用)
>     权重 $w \approx 1/(\Delta_2^2 + c)$，大误差样本的权重随 $\Delta_2$ 的平方衰减，模型几乎忽略大误差样本，更关注小误差（适用于误差分布集中在小范围的场景）。
>-   **当 $p \to 0$（即 $\gamma \to 1$）**：
>     权重 $w \approx 1$（因 $(\Delta_2^2 + c)^0 = 1$），损失退化为普通L2损失，对所有样本一视同仁（适用于误差分布均匀、无明显异常值的场景）。
>
>### **总结**
>
>$p$ 是自适应加权L2损失中的关键参数，通过调节权重随误差的衰减速度，控制模型对不同误差大小样本的关注程度。其取值由超参数 $\gamma$ 决定（$p = 1 - \gamma$），实际应用中需根据误差分布的特点（如是否存在大量异常值）选择合适的 $p$（或 $\gamma$）。
>
>

### 值得尝试的采样时间方法

#### 1. **均匀分布采样（Uniform Sampling）**

最简单的尝试; 效果一般般. 

**指标**：
 从时间范围 $[t_{\text{min}}, t_{\text{max}}]$ 中均匀采样两个时间步 $r$ 和 $t'$，再通过 $\max$-$\min$ 确保 $t > r$。具体步骤：

$$
r, t' \sim \mathcal{U}(t_{\text{min}}, t_{\text{max}}), \quad t = \max(r, t'), \quad r = \min(r, t')
$$

适用于时间步无偏分布的场景（如时间序列中各时间步重要性相近），实现简单且覆盖所有可能的时间对。

#### 2. **对数正态（Logit-Normal）分布采样**

论文中说:$lognorm(-0.4, 1.0)$比较好 我们还可以试试:(-0.2, 1.0) / (-0.4, 1.2) 这两组实验

还说 : `Given a sampled pair, we assign the larger value to
t and the smaller to r. We set a certain portion of random samples with r = t.`

并且,论文实验表明,The 0% (r != t) reduces to the standard Flow Matching baseline,非常不好; 25% / 50% (r! = t) 会比较好.

**指标**：
 先从正态分布 $\mathcal{N}(\mu, \sigma^2)$ 采样 $z$，再通过逻辑函数映射至 $(0,1)$ 区间，最后缩放至时间范围 $[t_{\text{min}}, t_{\text{max}}]$。具体步骤：
$$
z \sim \mathcal{N}(\mu, \sigma^2), \quad u = \frac{1}{1 + e^{-z}}, \quad r = t_{\text{min}} + u(t_{\text{max}} - t_{\text{min}}), \quad t = t_{\text{min}} + (1 - u)(t_{\text{max}} - t_{\text{min}})
$$

其中 $u \in (0,1)$ 保证 $t > r$。该方法适用于时间步倾向于聚集在两端（如早期或晚期）的场景（例如长期预测中更关注远期时间步）。

#### 3. **时间衰减指数分布采样（Time-Decay Exponential Sampling）**

有时间谁来玩一玩它.

**指标**：
 假设时间步越接近参考点（如当前时间 $t_0$）越重要，采用指数分布采样。概率密度函数为：
$$
p(t) \propto e^{-\lambda |t - t_0|}, \quad t \in [0, T]
$$

其中 $\lambda > 0$ 控制衰减速度（$\lambda$ 越大，近期时间步概率越高）。归一化后，从该分布中采样 $r$ 和 $t$，并确保 $t > r$。适用于时间序列预测中近期数据主导的场景（如短期预测需重点关注最近几小时/天的数据）。